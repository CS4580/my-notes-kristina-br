{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 7 Notes: Metrics and Model Development\n",
    "\n",
    "## Metrics\n",
    "\n",
    "Metrics should be unbiased, universal, and concise.\n",
    "\n",
    "    1. A way to obtain similar responses\n",
    "    2. A way to measure the performance\n",
    "    3. A way to measure prediction\n",
    "\n",
    "For our sample analysis we will use `KNN` K-Nearest Neighbor\n",
    "    - K is an arbitrary pick\n",
    "    - Need a \"base case\"\n",
    "    - Compare the neighbors\n",
    "    - Sort the results\n",
    "\n",
    "Data set for this analysis:\n",
    "```bash\n",
    "icarus.cs.weber.edu:~hvalle/cs4580/data/movies.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import get_data as gt  # download and load data\n",
    "import Levenshtein  # Levenshtein distance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Constants\n",
    "K = 10  # number of closest matches\n",
    "BASE_CASE_ID = 88763  # IMDB id for 'Back to the Future'\n",
    "SECOND_CASE_ID = 89530  # IMDB id for 'Mad Max Beyond Thunderdome'\n",
    "BASE_YEAR = 1980  # year for 'Back to the Future'\n",
    "\n",
    "METRIC1_WT = 0.2  # weight for cosine similarity\n",
    "METRIC2_WT = 0.8  # weight for weighted Jaccard similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN-Euclidean Distance\n",
    "\n",
    "The Euclidean distance is the distance between points \n",
    "in `N-dimensional` space.\n",
    "\n",
    "Formula\n",
    "\n",
    "$\n",
    "d(p, q) = \\sqrt{\\sum_{i=1}^n (q_i = p_i)^2}\n",
    "$\n",
    "\n",
    "where\n",
    "- $p = (p_1, p_2, \\dots p_n)$\n",
    "- $q = (q_1, q_2, \\dots, q_n)$\n",
    "\n",
    "#### Task:\n",
    "Find the distance between these points:\n",
    "- x = (0,0)\n",
    "- y = (4,4)\n",
    "\n",
    "Distance = 5.65685..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(base_case_year: int, comparator_year: int):\n",
    "    \"\"\"Euclidean distance between two years\n",
    "\n",
    "    Args:\n",
    "        base_case_year (int): Base case year\n",
    "        comparator_year (int): Comparator year\n",
    "\n",
    "    Returns:\n",
    "        int: Absolute difference between the two years\n",
    "    \"\"\"\n",
    "    return abs(base_case_year - comparator_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with Jaccard Similarity Index\n",
    "Compares members of two individual sets to determin which members are `shared` and which are `distinct`.\n",
    "The index measures the similarity between the two sets.\n",
    "\n",
    "$$\n",
    "J(A, B) = \\frac{|A \\cap B|}{|A \\cup B|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with Weighted Jaccard Simlarity Index\n",
    "The traditional Jaccard works well when doing \n",
    "`one-to-one` comparisons between a category.\n",
    "\n",
    "One solution is the `weighted` version.\n",
    "- build a ditionary for `each genre` of the movies in our preferred list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see\n",
    "def weighted_jaccard_weighted():\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with Levenshtein Distance\n",
    "an initial sequence to a target sequence.\n",
    "\n",
    "- It is used to determine the difference between two sequences (strings)\n",
    "- It is the distance between two words (minimum number of digits edits)\n",
    "  - insertions, deletions, or substitutions\n",
    "\n",
    "$$\n",
    "D(i, j) = \n",
    "\\begin{cases}\n",
    "j & \\text{if } i = 0 \\\\\n",
    "i & \\text{if } j = 0 \\\\\n",
    "D(i-1, j-1) & \\text{if } s[i] = t[j] \\\\\n",
    "1 + \\min \\{D(i-1, j), D(i, j-1), D(i-1, j-1)\\} & \\text{if } s[i] \\neq t[j]\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For example:\n",
    "\n",
    "Consider these strings:\n",
    "\n",
    "- s = 'kitten'\n",
    "- t = 'sitting'\n",
    "\n",
    "Find the `Levenshtein` Distance\n",
    "1. Substitute `k`with `s` in `kitten` -> `sitten`(1 substitution)\n",
    "2. Substitute `e` with `i` in `sitten` -> `sittin` (1 substitution)\n",
    "3. Insert `g` at the end of `sittin` -> `sitting` (1 insertion)\n",
    "\n",
    "Result is 3 edits, so the distance is $ = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see\n",
    "def knn_levenshtein_title():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need this package:\n",
    "```bash\n",
    "# VE must be running python 3.11 or less\n",
    "pip install Levenshtein\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Cosine Similarity Distance\n",
    "\n",
    "This is used to measure the cosine of the angle between two vectors in a \n",
    "multi-dimensional space. This is commonly used in text analysis to measure \n",
    "similarities between documents.\n",
    "\n",
    "$$\n",
    "\\text{Cosine Similarity} = \\cos(\\theta) = \\\\\n",
    "\\frac{A \\cdot B}{|A| |B|}\n",
    "= \\frac{\\sum_{i=1}^{n} A_i B_i}{ \\sqrt{sum_{i=1} A_i^2} \\cdot \\sqrt{\\sum_{i=1}^{n} B_i^2}}\n",
    "$$\n",
    "\n",
    "Where\n",
    "- $ A \\cdot B$ is the dot product of vectors $A$ and $B$\n",
    "- $|A|$ and $|B|$ are the agnitude (or Euclidean norms) of vectors $A$ and $B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_and_weighted_jaccard(df: pd.DataFrame, plots: str, comparator_movie: pd.core.series.Series,):\n",
    "    # Perform the cosine similiarty and weighted Jaccard metrics:\n",
    "    cs_result = cosine_similarity_function(plots, comparator_movie[\"plot\"])\n",
    "    weighted_dictionary = _get_weighted_jaccard_similarity_dict(df)\n",
    "    wjs_result = weighted_jaccard_similarity(\n",
    "        df, comparator_movie[\"genres\"]\n",
    "    )\n",
    "\n",
    "    # Normalization:\n",
    "    # The weighted Jaccard similarity result has a range from 0.0 to 1.0.\n",
    "    # The cosine similarity result has a range from -1.0 to 1.0. We need to change the range for the cosine similarity result.\n",
    "    # First, add 1 to the cosine similarity result so that it has a range from 0.0 to 2.0\n",
    "    # Second, divide the result by 2.0 so that it has a range from 0.0 to 1.0:\n",
    "    cs_result = (cs_result + 1) / 2.0\n",
    "\n",
    "    # Weights:\n",
    "    # Use a weight of 0.2 (20%) for the cosine similarity result:\n",
    "    cs_result *= METRIC1_WT\n",
    "    # Use a weight of 0.8 (80%) for the weighted Jaccard similarity result:\n",
    "    wjs_result *= METRIC2_WT\n",
    "    return wjs_result + cs_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_function(base_case_plot, comparator_plot):\n",
    "    # this line will convert the plots from strings to vectors in a single matrix:\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(\n",
    "        (base_case_plot, comparator_plot))\n",
    "    results = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "    return results[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Combining Metrics and Filtering Conditions\n",
    "\n",
    "Two main concerns with `filtering`:\n",
    "- Making it too complicated (think hard SQL queries)\n",
    "- too strict (end up with no results)\n",
    "\n",
    "Combine `metrics` to generate `one` result:\n",
    "- Weight each metric\n",
    "    - Should metrics contribute equally? (50%-50%, 80%-80%)\n",
    "- Normalization of the combine metric\n",
    "    - Make sure they have the same range\n",
    "\n",
    "For our example, we will use:\n",
    "- `Cosine`: Use 20% of the `plot`\n",
    "- `Weighted Jaccard`: Use 80% of `genres`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See\n",
    "def cosine_and_weighted_jaccard(df: pd.DataFrame, plots: str, comparator_movie: pd.core.series.Series,):\n",
    "    # Perform the cosine similiarty and weighted Jaccard metrics:\n",
    "    cs_result = cosine_similarity_function(plots, comparator_movie[\"plot\"])\n",
    "    weighted_dictionary = _get_weighted_jaccard_similarity_dict(df)\n",
    "    wjs_result = weighted_jaccard_similarity(\n",
    "        df, comparator_movie[\"genres\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Metrics\n",
    "\n",
    "If I predict that it will snow tomorrow, to check my answer I have to wait until it's tomorrow and see if it snows.\n",
    "\n",
    "A **prediction** is simply a guess about what is going to transpire. One prediction is `yes` or `no`.\n",
    "\n",
    "How do we measure the `accuracy` of the prediction?\n",
    "\n",
    "New file:\n",
    "```bash\n",
    "accuracy_metric.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "This is done to measure how well your classification model is. This model could be `binary` or `multi-class`. Each entry in a confusion matrix represents a specific combination `predicted vs actual` classes.\n",
    "\n",
    "For binary classification, you have `four` parts:\n",
    "- `True Positive (TP)`: Correctly predicted positive observations\n",
    "- `True Negative (TN)`: Correctly predicted negative observations\n",
    "- `False Positive (FP)`: Incorrectly predicted positive observations (also known as `Type I Error`)\n",
    "- `False Negative (FN)`: Incorrectly preedicted negative observations (aka `Type II Error`)\n",
    "\n",
    "The structure of the matrix is as follows: \n",
    "\n",
    "|       | Predicted Positive | Predicted Negative|\n",
    "|-------|--------------------|-------------------|\n",
    "|Actual Positive | True Positive (TP) | False Negative (FN) |\n",
    "|Actual Negative | False Positive (FP) | True Negative (TN) |\n",
    "\n",
    "Key metrics:\n",
    "- **Accuracy** = $\\frac{{TP + TN}}{{Tp + TN + FP + FN}}$\n",
    "- **Precision** = $\\frac{{TP}}{{TP + FP}}$ (useful for imbalance classes-- which means something like more yes's than no's)\n",
    "- **Recall** (or **Sensitivity**) = $\\frac{{TP}}{{TP + FN}}$\n",
    "- **F1 Score** = $2 \\times \\frac{{Precision \\times Recall}}{{Precision + Recall}}$ (also known as harmonic mean of Precision and Recall)\n",
    "\n",
    "New python file:\n",
    "```bash\n",
    "confusion_matrix.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
